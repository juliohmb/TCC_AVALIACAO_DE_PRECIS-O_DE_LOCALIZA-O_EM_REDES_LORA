{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ab9ac6-dc17-462e-9cfb-9d67f1440b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas carregadas com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# Bibliotecas de Visualização\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "print(\"Bibliotecas carregadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3473bad-3b10-4512-b630-915d10c39895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurações carregadas de 'config.json'.\n",
      "Modo FIXO ativado.\n"
     ]
    }
   ],
   "source": [
    "# Configurações de Ambiente e Visualização\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Criação do diretório para imagens estáticas\n",
    "OUTPUT_IMG_DIR = \"imagens\"\n",
    "os.makedirs(OUTPUT_IMG_DIR, exist_ok=True)\n",
    "\n",
    "# Configurações Padrão (Fallback)\n",
    "DEFAULT_CONFIG = {\n",
    "    \"hdop_threshold\": 5.0,\n",
    "    \"bounds\": {\n",
    "        \"min_lat\": 51.185,\n",
    "        \"max_lat\": 51.2361,\n",
    "        \"min_lon\": 4.325,\n",
    "        \"max_lon\": 4.459\n",
    "    },\n",
    "\n",
    "    \"min_gateways_rssi\": 3,\n",
    "    \"min_gateways_tdoa\": 3,\n",
    "    \"min_gateways_ransac\": 4,\n",
    "\n",
    "    \"rssi_ref\": -21.7,\n",
    "    \"path_loss_n\": 2.70,\n",
    "\n",
    "    \"ransac_iterations\": 50,\n",
    "    \"ransac_consensus_threshold_m\": 500,\n",
    "\n",
    "    \"kalman_q_val\": 0.1,\n",
    "    \"kalman_r_cl\": 500,\n",
    "    \"kalman_r_wcl\": 300,\n",
    "    \"kalman_r_mlat_lse\": 250,\n",
    "    \"kalman_r_tdoa_lm\": 100,\n",
    "    \"kalman_r_tdoa_ransac\": 50,\n",
    "    \"kalman_r_tdoa_bestgeom\": 50,\n",
    "\n",
    "    \"kalman_warmup_steps\": 10, \n",
    "\n",
    "    \"total_area_km2\": 53.07,\n",
    "\n",
    "    \"nn_config\": {\n",
    "        \"gt_interval_seconds\": 600,\n",
    "        \"hidden_neurons\": 10,\n",
    "        \"epochs\": 4000,\n",
    "        \"batch_size\": 32,\n",
    "        \"test_split_size\": 0.2,\n",
    "        \"validation_split_size\": 0.1,\n",
    "        \"patience_early_stop\": 50,\n",
    "        \"default_rssi\": -120.0,\n",
    "        \"model_save_path\": \"modelo_nn_lora_gt.h5\",\n",
    "        \"input_scaler_save_path\": \"input_scaler.joblib\",\n",
    "        \"output_scaler_save_path\": \"output_scaler.joblib\"\n",
    "    },\n",
    "    \"use_calibrated_rssi_params\": False, \n",
    "    \"calibration_file_path\": \"gateway_calibration_results.json\"\n",
    "}\n",
    "\n",
    "# Carregamento de Configurações\n",
    "try:\n",
    "    with open('config.json', 'r') as f:\n",
    "        CONFIG = json.load(f)\n",
    "    print(\"Configurações carregadas de 'config.json'.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Aviso: 'config.json' não encontrado. Usando padrões.\")\n",
    "    CONFIG = DEFAULT_CONFIG\n",
    "\n",
    "# Constantes Físicas\n",
    "TOTAL_AREA_M2 = CONFIG.get('total_area_km2', 53.0) * 1e6\n",
    "C_LIGHT = 299792458.0\n",
    "\n",
    "# Configuração de Calibração RSSI\n",
    "USE_CALIBRATED_RSSI = CONFIG.get('use_calibrated_rssi_params', False)\n",
    "CALIBRATION_PARAMS = {\"global_average\": {}, \"gateway_parameters\": {}}\n",
    "\n",
    "if USE_CALIBRATED_RSSI:\n",
    "    calib_path = CONFIG.get('calibration_file_path', 'gateway_calibration_results.json')\n",
    "    try:\n",
    "        with open(calib_path, 'r') as f:\n",
    "            CALIBRATION_PARAMS = json.load(f)\n",
    "        \n",
    "        if \"global_average\" not in CALIBRATION_PARAMS:\n",
    "             CALIBRATION_PARAMS[\"global_average\"] = {\n",
    "                 'A_avg': CONFIG.get('rssi_ref', -21.7), \n",
    "                 'n_avg': CONFIG.get('path_loss_n', 2.70)\n",
    "             }\n",
    "        print(f\"Modo CALIBRADO ativado usando: {calib_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar calibração ({e}). Revertendo para modo FIXO.\")\n",
    "        USE_CALIBRATED_RSSI = False\n",
    "\n",
    "if not USE_CALIBRATED_RSSI:\n",
    "    CALIBRATION_PARAMS[\"global_average\"] = {\n",
    "        'A_avg': CONFIG.get('rssi_ref', -21.7), \n",
    "        'n_avg': CONFIG.get('path_loss_n', 2.70)\n",
    "    }\n",
    "    print(\"Modo FIXO ativado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd79642f-459e-48e6-bcac-c97868b2fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calcula a distância (metros) entre duas coordenadas (Haversine).\"\"\"\n",
    "    if any(v is None for v in [lat1, lon1, lat2, lon2]):\n",
    "        return float('inf')\n",
    "        \n",
    "    R = 6371000\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "    \n",
    "    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def latlon_to_xy(lat, lon, ref_lat, ref_lon):\n",
    "    \"\"\"Projeção local plana (equirretangular simplificada) em metros.\"\"\"\n",
    "    if any(v is None for v in [lat, lon]): return None, None\n",
    "    x = haversine(ref_lat, ref_lon, ref_lat, lon) * np.sign(lon - ref_lon)\n",
    "    y = haversine(ref_lat, ref_lon, lat, ref_lon) * np.sign(lat - ref_lat)\n",
    "    return x, y\n",
    "\n",
    "def xy_to_latlon(x, y, ref_lat, ref_lon):\n",
    "    \"\"\"Conversão inversa de XY metros para Lat/Lon.\"\"\"\n",
    "    R = 6371000\n",
    "    new_lat = ref_lat + math.degrees(y / R)\n",
    "    new_lon = ref_lon + math.degrees(x / (R * math.cos(math.radians(ref_lat))))\n",
    "    return new_lat, new_lon\n",
    "\n",
    "def is_within_bounds(lat, lon):\n",
    "    \"\"\"Verifica bounding box da área de interesse.\"\"\"\n",
    "    if lat is None or lon is None: return False\n",
    "    b = CONFIG['bounds']\n",
    "    return (b['min_lat'] <= lat <= b['max_lat']) and (b['min_lon'] <= lon <= b['max_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec85f71-55f1-4a72-8254-c8eae34ed9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter:\n",
    "    \"\"\"Filtro de Kalman Linear (Modelo Velocidade Constante - CV).\"\"\"\n",
    "    def __init__(self, dt=1.0, R_val=10000, Q_val=0.1):\n",
    "        self.F = np.eye(4) # Será atualizado com dt\n",
    "        self.H = np.array([[1, 0, 0, 0], [0, 1, 0, 0]])\n",
    "        self.Q = Q_val * np.eye(4)\n",
    "        self.R = R_val * np.eye(2)\n",
    "        self.P = 100 * np.eye(4)\n",
    "        self.x = np.zeros((4, 1))\n",
    "        self._update_dt(dt)\n",
    "\n",
    "    def _update_dt(self, dt):\n",
    "        self.F[0, 2] = dt\n",
    "        self.F[1, 3] = dt\n",
    "        self.F[2, 3] = 0 # CV model simplificado na matriz\n",
    "\n",
    "    def predict(self, dt=None):\n",
    "        if dt is not None: self._update_dt(dt)\n",
    "        self.x = self.F @ self.x\n",
    "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
    "\n",
    "    def update(self, z):\n",
    "        if z is None: return\n",
    "        y = z - self.H @ self.x\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
    "        self.x = self.x + K @ y\n",
    "        self.P = (np.eye(4) - K @ self.H) @ self.P\n",
    "\n",
    "\n",
    "class ARFLFusion:\n",
    "    \"\"\"Adaptive Robust Fusion Layer (baseado em Fabris et al. 2025).\"\"\"\n",
    "    def __init__(self, kf1, kf2):\n",
    "        self.kf1 = kf1\n",
    "        self.kf2 = kf2\n",
    "\n",
    "    def step(self, z1_k, z2_k, dt):\n",
    "        # 1. Predição Local\n",
    "        self.kf1.predict(dt)\n",
    "        self.kf2.predict(dt)\n",
    "        x1_p, P1_p = self.kf1.x, self.kf1.P\n",
    "        x2_p, P2_p = self.kf2.x, self.kf2.P\n",
    "\n",
    "        # 2. Predição Fundida (Covariância Inversa)\n",
    "        try:\n",
    "            P1_inv, P2_inv = np.linalg.inv(P1_p), np.linalg.inv(P2_p)\n",
    "            P_fused_p = np.linalg.inv(P1_inv + P2_inv)\n",
    "            x_fused_p = P_fused_p @ (P1_inv @ x1_p + P2_inv @ x2_p)\n",
    "        except np.linalg.LinAlgError:\n",
    "            return x1_p, P1_p # Fallback simples\n",
    "\n",
    "        # 3. Atualização Local Cruzada\n",
    "        x1_u, P1_u = self._local_update(self.kf1, x_fused_p, P_fused_p, z1_k)\n",
    "        x2_u, P2_u = self._local_update(self.kf2, x_fused_p, P_fused_p, z2_k)\n",
    "\n",
    "        # 4. Estimativa Final Fundida\n",
    "        if z1_k is None and z2_k is None:\n",
    "            x_post, P_post = x_fused_p, P_fused_p\n",
    "        elif z1_k is None:\n",
    "            x_post, P_post = x2_u, P2_u\n",
    "        elif z2_k is None:\n",
    "            x_post, P_post = x1_u, P1_u\n",
    "        else:\n",
    "            P1_u_inv, P2_u_inv = np.linalg.inv(P1_u), np.linalg.inv(P2_u)\n",
    "            P_post = np.linalg.inv(P1_u_inv + P2_u_inv)\n",
    "            x_post = P_post @ (P1_u_inv @ x1_u + P2_u_inv @ x2_u)\n",
    "\n",
    "        # 5. Feedback Loop (Atualiza filtros internos)\n",
    "        self.kf1.x, self.kf1.P = x1_u, P1_u\n",
    "        self.kf2.x, self.kf2.P = x2_u, P2_u\n",
    "\n",
    "        return x_post, P_post\n",
    "\n",
    "    def _local_update(self, kf, x_pred, P_pred, z):\n",
    "        if z is None: return x_pred, P_pred\n",
    "        H, R = kf.H, kf.R\n",
    "        S = H @ P_pred @ H.T + R\n",
    "        K = P_pred @ H.T @ np.linalg.inv(S)\n",
    "        x_up = x_pred + K @ (z - H @ x_pred)\n",
    "        P_up = (np.eye(4) - K @ H) @ P_pred\n",
    "        return x_up, P_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e341c072-802a-41a3-8d0b-f6e63e389178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rssi_to_distance(rssi, gw_id):\n",
    "    \"\"\"\n",
    "    Converte RSSI em distância (metros).\n",
    "    Usa parâmetros calibrados (A, n) se disponíveis, ou média global.\n",
    "    \"\"\"\n",
    "    if USE_CALIBRATED_RSSI:\n",
    "        # Busca params específicos ou usa fallback global\n",
    "        params = CALIBRATION_PARAMS['gateway_parameters'].get(gw_id, CALIBRATION_PARAMS['global_average'])\n",
    "        A = params.get('A_estimado', params.get('A_avg', CONFIG.get('rssi_ref', -58)))\n",
    "        n = params.get('n_estimado', params.get('n_avg', CONFIG.get('path_loss_n', 2.2)))\n",
    "    else:\n",
    "        # Modo Fixo\n",
    "        A = CALIBRATION_PARAMS['global_average']['A_avg']\n",
    "        n = CALIBRATION_PARAMS['global_average']['n_avg']\n",
    "    \n",
    "    # Evita divisão por zero\n",
    "    if n == 0: return float('inf')\n",
    "    \n",
    "    return 10**((A - rssi) / (10 * n))\n",
    "\n",
    "def weighted_centroid_localization(rssi_data, locations):\n",
    "    \"\"\"\n",
    "    Algoritmo WCL (Weighted Centroid Localization).\n",
    "    Peso = 1 / (distância ^ g).\n",
    "    \"\"\"\n",
    "    g = CONFIG.get('wcl_g_factor', 2.0)\n",
    "    num_lat, num_lon, den = 0.0, 0.0, 0.0\n",
    "    \n",
    "    for gw_id, rssi in rssi_data.items():\n",
    "        dist = rssi_to_distance(rssi, gw_id)\n",
    "        if dist <= 0: continue\n",
    "        \n",
    "        weight = dist ** (-g)\n",
    "        loc = locations[gw_id]\n",
    "        \n",
    "        num_lat += loc['latitude'] * weight\n",
    "        num_lon += loc['longitude'] * weight\n",
    "        den += weight\n",
    "        \n",
    "    if den > 0:\n",
    "        return num_lat / den, num_lon / den\n",
    "    return None, None\n",
    "\n",
    "def multilateration_rssi_lse(distances, locations, ref_lat, ref_lon):\n",
    "    \"\"\"\n",
    "    Multilateração baseada em distâncias RSSI usando Mínimos Quadrados Lineares (LSE).\n",
    "    Linearização do sistema de equações de círculos.\n",
    "    \"\"\"\n",
    "    ids = list(distances.keys())\n",
    "    if len(ids) < 3: return None, None # Requer mínimo de 3 âncoras\n",
    "\n",
    "    # Converte gateways para XY local\n",
    "    gws_xy = {gid: latlon_to_xy(l['latitude'], l['longitude'], ref_lat, ref_lon) for gid, l in locations.items()}\n",
    "    \n",
    "    ref_id = ids[0]\n",
    "    x1, y1 = gws_xy[ref_id]\n",
    "    r1 = distances[ref_id]\n",
    "    \n",
    "    G, h = [], []\n",
    "    for gid in ids[1:]:\n",
    "        xi, yi = gws_xy[gid]\n",
    "        ri = distances[gid]\n",
    "        \n",
    "        # Montagem da matriz Ax = b (Linearização)\n",
    "        G.append([-2*(xi - x1), -2*(yi - y1)])\n",
    "        h.append(ri**2 - r1**2 - (xi**2 + yi**2) + (x1**2 + y1**2))\n",
    "        \n",
    "    try:\n",
    "        # Resolve o sistema linear\n",
    "        pos = np.linalg.lstsq(np.array(G), np.array(h), rcond=None)[0]\n",
    "        return pos[0], pos[1]\n",
    "    except np.linalg.LinAlgError:\n",
    "        return None, None\n",
    "\n",
    "def solve_tdoa(sample_gws, gw_locs, ref_lat, ref_lon):\n",
    "    \"\"\"\n",
    "    Solver TDoA usando Levenberg-Marquardt (Least Squares não-linear).\n",
    "    Base: Minimizar a diferença entre (distância medida via tempo) e (distância geométrica).\n",
    "    \"\"\"\n",
    "    # Garante ordenação por tempo para definir a referência (t0) corretamente\n",
    "    sample_gws.sort(key=lambda g: g['rx_time_ns'])\n",
    "    ref_gw = sample_gws[0]\n",
    "    \n",
    "    # Dados de entrada em XY\n",
    "    gws_xy = [latlon_to_xy(gw_locs[g['id']]['latitude'], gw_locs[g['id']]['longitude'], ref_lat, ref_lon) for g in sample_gws]\n",
    "    ref_pos = np.array(gws_xy[0])\n",
    "    others_pos = gws_xy[1:]\n",
    "    \n",
    "    # Diferenças de distância medidas (convertidas de nanosegundos)\n",
    "    # delta_d = c * (t_i - t_ref)\n",
    "    delta_d_measured = [(g['rx_time_ns'] - ref_gw['rx_time_ns']) * 1e-9 * C_LIGHT for g in sample_gws[1:]]\n",
    "\n",
    "    # Função de resíduo para o otimizador\n",
    "    def residuals(est_pos, ref_p, other_ps, d_measures):\n",
    "        # Distância estimada até a referência\n",
    "        d_ref_est = np.linalg.norm(est_pos - ref_p)\n",
    "        \n",
    "        errors = []\n",
    "        for op, d_meas in zip(other_ps, d_measures):\n",
    "            # Distância estimada até o gateway i\n",
    "            d_i_est = np.linalg.norm(est_pos - op)\n",
    "            # Diferença geométrica estimada\n",
    "            delta_d_est = d_i_est - d_ref_est\n",
    "            # Erro = Modelo - Real\n",
    "            errors.append(delta_d_est - d_meas)\n",
    "        return errors\n",
    "\n",
    "    # Chute inicial: média das posições dos gateways (centroide)\n",
    "    initial_guess = np.mean(gws_xy, axis=0)\n",
    "    \n",
    "    try:\n",
    "        result = least_squares(\n",
    "            residuals, \n",
    "            initial_guess, \n",
    "            args=(ref_pos, others_pos, delta_d_measured), \n",
    "            method='lm'\n",
    "        )\n",
    "        return result.x[0], result.x[1]\n",
    "    except ValueError:\n",
    "        return None, None\n",
    "\n",
    "def tdoa_ransac(gps_gws, gw_locs, ref_lat, ref_lon):\n",
    "    \"\"\"\n",
    "    TDoA com RANSAC (Random Sample Consensus) para remoção de outliers.\n",
    "    \"\"\"\n",
    "    # 1. Preparação\n",
    "    if len(gps_gws) < CONFIG['min_gateways_ransac']: return None, None\n",
    "    \n",
    "    # Ordena globalmente para garantir referência consistente nos cálculos de erro\n",
    "    gps_gws.sort(key=lambda g: g['rx_time_ns'])\n",
    "    \n",
    "    # Cache das posições XY para performance\n",
    "    gws_xy_map = {\n",
    "        g['id']: np.array(latlon_to_xy(gw_locs[g['id']]['latitude'], gw_locs[g['id']]['longitude'], ref_lat, ref_lon)) \n",
    "        for g in gps_gws\n",
    "    }\n",
    "    \n",
    "    best_model_pos = None\n",
    "    max_inliers = 0\n",
    "    threshold = CONFIG['ransac_consensus_threshold_m']\n",
    "    \n",
    "    # 2. Loop RANSAC\n",
    "    for _ in range(CONFIG['ransac_iterations']):\n",
    "        try:\n",
    "            # Amostra aleatória mínima (ex: 3 ou 4 gateways)\n",
    "            sample = random.sample(gps_gws, CONFIG['min_gateways_tdoa'])\n",
    "            \n",
    "            # Gera modelo (posição candidata)\n",
    "            model_x, model_y = solve_tdoa(sample, gw_locs, ref_lat, ref_lon)\n",
    "            if model_x is None: continue\n",
    "            \n",
    "            model_pos = np.array([model_x, model_y])\n",
    "            \n",
    "            # 3. Passo de Consenso (Verificação de Inliers)\n",
    "            current_inliers_count = 0\n",
    "            \n",
    "            # Distância do modelo até o gateway de referência (índice 0 da lista global ordenada)\n",
    "            # Nota: TDoA requer uma referência comum para calcular os deltas\n",
    "            ref_gw_global = gps_gws[0] \n",
    "            ref_pos_xy = gws_xy_map[ref_gw_global['id']]\n",
    "            dist_ref_model = np.linalg.norm(model_pos - ref_pos_xy)\n",
    "            \n",
    "            for gw in gps_gws:\n",
    "                # Pula o próprio gw de referência\n",
    "                if gw['id'] == ref_gw_global['id']: \n",
    "                    current_inliers_count += 1\n",
    "                    continue\n",
    "\n",
    "                # a. Diferença de distância TEÓRICA (baseada no modelo)\n",
    "                gw_pos_xy = gws_xy_map[gw['id']]\n",
    "                dist_gw_model = np.linalg.norm(model_pos - gw_pos_xy)\n",
    "                delta_d_model = dist_gw_model - dist_ref_model\n",
    "                \n",
    "                # b. Diferença de distância MEDIDA (baseada no tempo)\n",
    "                delta_d_measured = (gw['rx_time_ns'] - ref_gw_global['rx_time_ns']) * 1e-9 * C_LIGHT\n",
    "                \n",
    "                # c. Verifica resíduo\n",
    "                if abs(delta_d_model - delta_d_measured) < threshold:\n",
    "                    current_inliers_count += 1\n",
    "            \n",
    "            # 4. Atualiza melhor modelo\n",
    "            if current_inliers_count > max_inliers:\n",
    "                max_inliers = current_inliers_count\n",
    "                best_model_pos = (model_x, model_y)\n",
    "                \n",
    "        except (ValueError, np.linalg.LinAlgError):\n",
    "            continue\n",
    "            \n",
    "    # Retorna a posição gerada pelo melhor consenso\n",
    "    return best_model_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9fa1fee-ebf0-4bd6-8bd1-1e5c2b979e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset pronto: 23 dispositivos identificados.\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    try:\n",
    "        with open('lorawan_antwerp_gateway_locations.json', 'r') as f:\n",
    "            gw_locs = json.load(f)\n",
    "        df = pd.read_json('lorawan_antwerp_2019_dataset.json')\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro fatal: {e.filename} não encontrado.\")\n",
    "        return None, None\n",
    "\n",
    "    # Pré-processamento\n",
    "    df = df[df['hdop'] <= CONFIG['hdop_threshold']].copy()\n",
    "    \n",
    "    # Extração segura de timestamp\n",
    "    df['timestamp'] = pd.to_datetime([\n",
    "        g[0]['rx_time']['time'] if g and 'rx_time' in g[0] else None \n",
    "        for g in df['gateways']\n",
    "    ], utc=True).tz_convert(None)\n",
    "    \n",
    "    df.dropna(subset=['timestamp', 'dev_eui', 'latitude', 'longitude'], inplace=True)\n",
    "    df.sort_values(['dev_eui', 'timestamp'], inplace=True)\n",
    "    \n",
    "    return df.groupby('dev_eui'), gw_locs\n",
    "\n",
    "tracks_grp, gateway_locations = load_dataset()\n",
    "if tracks_grp:\n",
    "    print(f\"Dataset pronto: {len(tracks_grp)} dispositivos identificados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39025f24-9d74-43b2-868b-f9679aa077c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1b5d9dda6149f0b181119fd5b4c526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simulando Trilhas:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulação Finalizada. Total de amostras: 127341\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "viz_list = []\n",
    "\n",
    "if tracks_grp:\n",
    "    for dev_id, track in tqdm(tracks_grp, desc=\"Simulando Trilhas\"):\n",
    "        if len(track) < CONFIG['kalman_warmup_steps']: continue\n",
    "\n",
    "        # Inicialização de Filtros\n",
    "        filters = {\n",
    "            'WCL': KalmanFilter(R_val=CONFIG['kalman_r_wcl']**2),\n",
    "            'MLAT-LSE': KalmanFilter(R_val=CONFIG['kalman_r_mlat_lse']**2),\n",
    "            'TDoA-LM': KalmanFilter(R_val=CONFIG['kalman_r_tdoa_lm']**2),\n",
    "            'TDoA-RANSAC': KalmanFilter(R_val=CONFIG['kalman_r_tdoa_ransac']**2)\n",
    "        }\n",
    "        arfl = ARFLFusion(\n",
    "            KalmanFilter(R_val=CONFIG['kalman_r_wcl']**2), \n",
    "            KalmanFilter(R_val=CONFIG['kalman_r_tdoa_lm']**2)\n",
    "        )\n",
    "\n",
    "        # Referência Local\n",
    "        ref_lat, ref_lon = track.iloc[0][['latitude', 'longitude']]\n",
    "        last_ts_indep = None\n",
    "        last_ts_arfl = None\n",
    "        warmup = CONFIG['kalman_warmup_steps']\n",
    "\n",
    "        for i, (idx, row) in enumerate(track.iterrows()):\n",
    "            gt_x, gt_y = latlon_to_xy(row['latitude'], row['longitude'], ref_lat, ref_lon)\n",
    "            \n",
    "            # Delta T\n",
    "            curr_ts = row['timestamp']\n",
    "            dt = (curr_ts - last_ts_indep).total_seconds() if last_ts_indep else 1.0\n",
    "            if dt <= 0: dt = 1.0\n",
    "            last_ts_indep = curr_ts\n",
    "\n",
    "            packet_res = {\n",
    "                'dev_id': dev_id, 'ts': curr_ts, \n",
    "                'gt_lat': row['latitude'], 'gt_lon': row['longitude']\n",
    "            }\n",
    "            errors = {}\n",
    "            \n",
    "            # --- Medições ---\n",
    "            # RSSI\n",
    "            rssi_map = {gw['id']: gw['rssi'] for gw in row['gateways'] if gw['id'] in gateway_locations}\n",
    "            meas_latlon, meas_xy = {}, {}\n",
    "            \n",
    "            if len(rssi_map) >= CONFIG['min_gateways_rssi']:\n",
    "                wcl = weighted_centroid_localization(rssi_map, gateway_locations)\n",
    "                if wcl[0]: meas_latlon['WCL'] = wcl\n",
    "                \n",
    "                dists = {k: rssi_to_distance(v, k) for k,v in rssi_map.items()}\n",
    "                locs = {k: gateway_locations[k] for k in dists}\n",
    "                lse = multilateration_rssi_lse(dists, locs, ref_lat, ref_lon)\n",
    "                if lse[0]: meas_xy['MLAT-LSE'] = lse\n",
    "\n",
    "            # TDoA\n",
    "            gps_gws = [{**g, 'rx_time_ns': pd.to_datetime(g['rx_time']['time']).value} \n",
    "                       for g in row['gateways'] if g.get('rx_time', {}).get('ts_type') == 'GPS_RADIO']\n",
    "            \n",
    "            if len(gps_gws) >= CONFIG['min_gateways_tdoa']:\n",
    "                lm = solve_tdoa(gps_gws, gateway_locations, ref_lat, ref_lon)\n",
    "                if lm[0]: meas_xy['TDoA-LM'] = lm\n",
    "            \n",
    "            if len(gps_gws) >= CONFIG['min_gateways_ransac']:\n",
    "                ransac = tdoa_ransac(gps_gws, gateway_locations, ref_lat, ref_lon)\n",
    "                if ransac and ransac[0]: meas_xy['TDoA-RANSAC'] = ransac\n",
    "\n",
    "            # --- Processamento Kalman Independente ---\n",
    "            for method, kf in filters.items():\n",
    "                kf.predict(dt)\n",
    "                z = None\n",
    "                \n",
    "                # Tenta obter medição XY\n",
    "                if method in meas_xy: \n",
    "                    z = np.array([[meas_xy[method][0]], [meas_xy[method][1]]])\n",
    "                elif method in meas_latlon:\n",
    "                    mx, my = latlon_to_xy(meas_latlon[method][0], meas_latlon[method][1], ref_lat, ref_lon)\n",
    "                    if mx: z = np.array([[mx], [my]])\n",
    "                \n",
    "                kf.update(z)\n",
    "                \n",
    "                if i > warmup and is_within_bounds(*xy_to_latlon(kf.x[0,0], kf.x[1,0], ref_lat, ref_lon)):\n",
    "                    err = math.sqrt((kf.x[0,0] - gt_x)**2 + (kf.x[1,0] - gt_y)**2)\n",
    "                    errors[f\"{method}+Kalman\"] = err\n",
    "                    packet_res[f\"{method}_est_lat\"], packet_res[f\"{method}_est_lon\"] = xy_to_latlon(kf.x[0,0], kf.x[1,0], ref_lat, ref_lon)\n",
    "\n",
    "            # --- Fusão ARFL ---\n",
    "            dt_arfl = (curr_ts - last_ts_arfl).total_seconds() if last_ts_arfl else 1.0\n",
    "            if dt_arfl <= 0: dt_arfl = 1.0\n",
    "            \n",
    "            z_wcl = None\n",
    "            if 'WCL' in meas_latlon:\n",
    "                wx, wy = latlon_to_xy(*meas_latlon['WCL'], ref_lat, ref_lon)\n",
    "                if wx: z_wcl = np.array([[wx], [wy]])\n",
    "            \n",
    "            z_tdoa = None\n",
    "            if 'TDoA-LM' in meas_xy:\n",
    "                z_tdoa = np.array([[meas_xy['TDoA-LM'][0]], [meas_xy['TDoA-LM'][1]]])\n",
    "\n",
    "            # Executa fusão se houver pelo menos uma medição válida e novo timestamp\n",
    "            if (z_wcl is not None or z_tdoa is not None):\n",
    "                x_arfl, _ = arfl.step(z_wcl, z_tdoa, dt_arfl)\n",
    "                last_ts_arfl = curr_ts # Atualiza timestamp apenas se houve step\n",
    "                \n",
    "                if i > warmup:\n",
    "                    fx, fy = x_arfl[0,0], x_arfl[1,0]\n",
    "                    if is_within_bounds(*xy_to_latlon(fx, fy, ref_lat, ref_lon)):\n",
    "                        errors['ARFL'] = math.sqrt((fx - gt_x)**2 + (fy - gt_y)**2)\n",
    "                        packet_res['ARFL_est_lat'], packet_res['ARFL_est_lon'] = xy_to_latlon(fx, fy, ref_lat, ref_lon)\n",
    "\n",
    "            if errors:\n",
    "                results_list.append(errors)\n",
    "                # Adiciona erros ao pacote de visualização para facilitar cor/tamanho\n",
    "                packet_res.update(errors) \n",
    "                viz_list.append(packet_res)\n",
    "\n",
    "    df_results = pd.DataFrame(results_list)\n",
    "    df_viz = pd.DataFrame(viz_list)\n",
    "    print(f\"Simulação Finalizada. Total de amostras: {len(df_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d9fb60-0697-49b5-81e9-f9d7118dabd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n\nKaleido requires Google Chrome to be installed.\n\nEither download and install Chrome yourself following Google's instructions for your operating system,\nor install it from your terminal by running:\n\n    $ plotly_get_chrome\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mChromeNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[31mChromeNotFoundError\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChromeNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/plotly/io/_kaleido.py:398\u001b[39m, in \u001b[36mto_image\u001b[39m\u001b[34m(fig, format, width, height, scale, validate, engine)\u001b[39m\n\u001b[32m    388\u001b[39m     height = (\n\u001b[32m    389\u001b[39m         height\n\u001b[32m    390\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m fig_dict.get(\u001b[33m\"\u001b[39m\u001b[33mlayout\u001b[39m\u001b[33m\"\u001b[39m, {}).get(\u001b[33m\"\u001b[39m\u001b[33mheight\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m defaults.default_height\n\u001b[32m    396\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     img_bytes = \u001b[43mkaleido\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalc_fig_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfig_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtopojson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtopojson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkopts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkopts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ChromeNotFoundError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/kaleido/__init__.py:171\u001b[39m, in \u001b[36mcalc_fig_sync\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sync_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43moneshot_async_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalc_fig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/kaleido/_sync_server.py:131\u001b[39m, in \u001b[36moneshot_async_run\u001b[39m\u001b[34m(func, args, kwargs)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m res\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/kaleido/_sync_server.py:122\u001b[39m, in \u001b[36moneshot_async_run.<locals>.run\u001b[39m\u001b[34m(func, q, *args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     q.put(\u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# noqa: BLE001\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/asyncio/runners.py:195\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/asyncio/runners.py:118\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, coro, context)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/asyncio/base_events.py:725\u001b[39m, in \u001b[36mBaseEventLoop.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/kaleido/__init__.py:101\u001b[39m, in \u001b[36mcalc_fig\u001b[39m\u001b[34m(fig, path, opts, topojson, kopts)\u001b[39m\n\u001b[32m    100\u001b[39m kopts[\u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# should we force this?\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mKaleido\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkopts\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m k:\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m k.calc_fig(\n\u001b[32m    103\u001b[39m         fig,\n\u001b[32m    104\u001b[39m         path=path,\n\u001b[32m    105\u001b[39m         opts=opts,\n\u001b[32m    106\u001b[39m         topojson=topojson,\n\u001b[32m    107\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/kaleido/kaleido.py:164\u001b[39m, in \u001b[36mKaleido.__init__\u001b[39m\u001b[34m(self, page_generator, n, timeout, width, height, stepper, plotlyjs, mathjax, *args, **kwargs)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ChromeNotFoundError:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChromeNotFoundError(\n\u001b[32m    165\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKaleido v1 and later requires Chrome to be installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo install Chrome, use the CLI command `kaleido_get_chrome`, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor from Python, use either `kaleido.get_chrome()` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor `kaleido.get_chrome_sync()`.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    169\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mChromeNotFoundError\u001b[39;00m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# do this during open because it requires close\u001b[39;00m\n",
      "\u001b[31mChromeNotFoundError\u001b[39m: Kaleido v1 and later requires Chrome to be installed. To install Chrome, use the CLI command `kaleido_get_chrome`, or from Python, use either `kaleido.get_chrome()` or `kaleido.get_chrome_sync()`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     15\u001b[39m fig_box = px.box(\n\u001b[32m     16\u001b[39m     df_results, \n\u001b[32m     17\u001b[39m     points=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     18\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mDistribuição de Erro de Posicionamento por Método\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     labels={\u001b[33m\"\u001b[39m\u001b[33mvariable\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMétodo\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mErro (m)\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m fig_box.update_layout(template=\u001b[33m\"\u001b[39m\u001b[33mplotly_white\u001b[39m\u001b[33m\"\u001b[39m, showlegend=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43msave_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboxplot_erros.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 2. CDF (Cumulative Distribution Function)\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Preparar dados para CDF\u001b[39;00m\n\u001b[32m     26\u001b[39m cdf_data = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36msave_plot\u001b[39m\u001b[34m(fig, filename)\u001b[39m\n\u001b[32m      5\u001b[39m fig.update_layout(title=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      6\u001b[39m filepath = os.path.join(OUTPUT_IMG_DIR, filename)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Restaura título e exibe\u001b[39;00m\n\u001b[32m     10\u001b[39m fig.update_layout(title=layout_bkp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/plotly/basedatatypes.py:3895\u001b[39m, in \u001b[36mBaseFigure.write_image\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3891\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   3892\u001b[39m         warnings.warn(\n\u001b[32m   3893\u001b[39m             ENGINE_PARAM_DEPRECATION_MSG, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m\n\u001b[32m   3894\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3895\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/plotly/io/_kaleido.py:528\u001b[39m, in \u001b[36mwrite_image\u001b[39m\u001b[34m(fig, file, format, scale, width, height, validate, engine)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28mformat\u001b[39m = infer_format(path, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m    526\u001b[39m \u001b[38;5;66;03m# Request image\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[38;5;66;03m# Do this first so we don't create a file if image conversion fails\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m img_data = \u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;66;03m# Open file\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    540\u001b[39m     \u001b[38;5;66;03m# We previously failed to make sense of `file` as a pathlib object.\u001b[39;00m\n\u001b[32m    541\u001b[39m     \u001b[38;5;66;03m# Attempt to write to `file` as an open file descriptor.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/plotly/io/_kaleido.py:410\u001b[39m, in \u001b[36mto_image\u001b[39m\u001b[34m(fig, format, width, height, scale, validate, engine)\u001b[39m\n\u001b[32m    398\u001b[39m         img_bytes = kaleido.calc_fig_sync(\n\u001b[32m    399\u001b[39m             fig_dict,\n\u001b[32m    400\u001b[39m             opts=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    407\u001b[39m             kopts=kopts,\n\u001b[32m    408\u001b[39m         )\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ChromeNotFoundError:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(PLOTLY_GET_CHROME_ERROR_MSG)\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    413\u001b[39m     \u001b[38;5;66;03m# Kaleido v0\u001b[39;00m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ENABLE_KALEIDO_V0_DEPRECATION_WARNINGS:\n",
      "\u001b[31mRuntimeError\u001b[39m: \n\nKaleido requires Google Chrome to be installed.\n\nEither download and install Chrome yourself following Google's instructions for your operating system,\nor install it from your terminal by running:\n\n    $ plotly_get_chrome\n\n"
     ]
    }
   ],
   "source": [
    "def save_plot(fig, filename):\n",
    "    \"\"\"Salva gráfico em alta resolução sem título (para relatórios) e exibe interativo.\"\"\"\n",
    "    # Remove título para salvar arquivo limpo\n",
    "    layout_bkp = fig.layout.title.text\n",
    "    fig.update_layout(title=None)\n",
    "    filepath = os.path.join(OUTPUT_IMG_DIR, filename)\n",
    "    fig.write_image(filepath, scale=2)\n",
    "    \n",
    "    # Restaura título e exibe\n",
    "    fig.update_layout(title=layout_bkp)\n",
    "    fig.show()\n",
    "\n",
    "if not df_results.empty:\n",
    "    # 1. Boxplot de Erros (Comparativo Global)\n",
    "    fig_box = px.box(\n",
    "        df_results, \n",
    "        points=False,\n",
    "        title=\"Distribuição de Erro de Posicionamento por Método\",\n",
    "        labels={\"variable\": \"Método\", \"value\": \"Erro (m)\"}\n",
    "    )\n",
    "    fig_box.update_layout(template=\"plotly_white\", showlegend=False)\n",
    "    save_plot(fig_box, \"boxplot_erros.png\")\n",
    "\n",
    "    # 2. CDF (Cumulative Distribution Function)\n",
    "    # Preparar dados para CDF\n",
    "    cdf_data = []\n",
    "    methods = [c for c in df_results.columns if 'ARFL' in c or 'Kalman' in c]\n",
    "    \n",
    "    for method in methods:\n",
    "        sorted_errors = np.sort(df_results[method].dropna())\n",
    "        yvals = np.arange(len(sorted_errors)) / float(len(sorted_errors) - 1)\n",
    "        cdf_data.append(pd.DataFrame({'Erro (m)': sorted_errors, 'CDF': yvals, 'Método': method}))\n",
    "    \n",
    "    if cdf_data:\n",
    "        df_cdf = pd.concat(cdf_data)\n",
    "        fig_cdf = px.line(\n",
    "            df_cdf, x='Erro (m)', y='CDF', color='Método',\n",
    "            title=\"CDF - Probabilidade Cumulativa de Erro\",\n",
    "            range_x=[0, 500] # Foca na região de interesse (0-500m)\n",
    "        )\n",
    "        fig_cdf.update_layout(template=\"plotly_white\", yaxis_title=\"Probabilidade (P(X <= x))\")\n",
    "        save_plot(fig_cdf, \"cdf_erros.png\")\n",
    "\n",
    "    # 3. Visualização de Trajetória (Amostra do melhor dispositivo)\n",
    "    # Escolhe o dispositivo com mais pontos\n",
    "    if not df_viz.empty:\n",
    "        best_dev = df_viz['dev_id'].value_counts().idxmax()\n",
    "        df_track = df_viz[df_viz['dev_id'] == best_dev].sort_values('ts')\n",
    "        \n",
    "        fig_map = go.Figure()\n",
    "        \n",
    "        # Ground Truth\n",
    "        fig_map.add_trace(go.Scattermapbox(\n",
    "            lat=df_track['gt_lat'], lon=df_track['gt_lon'],\n",
    "            mode='lines+markers', name='Ground Truth',\n",
    "            marker=dict(size=6, color='black'), line=dict(width=2)\n",
    "        ))\n",
    "        \n",
    "        # ARFL\n",
    "        if 'ARFL_est_lat' in df_track.columns:\n",
    "            fig_map.add_trace(go.Scattermapbox(\n",
    "                lat=df_track['ARFL_est_lat'], lon=df_track['ARFL_est_lon'],\n",
    "                mode='lines+markers', name='ARFL Fusion',\n",
    "                marker=dict(size=5, color='blue', opacity=0.7)\n",
    "            ))\n",
    "            \n",
    "        # Configuração do Mapa (OpenStreetMap gratuito)\n",
    "        fig_map.update_layout(\n",
    "            mapbox_style=\"open-street-map\",\n",
    "            mapbox=dict(\n",
    "                center=dict(lat=df_track['gt_lat'].mean(), lon=df_track['gt_lon'].mean()),\n",
    "                zoom=13\n",
    "            ),\n",
    "            title=f\"Trajetória: Dispositivo {best_dev}\",\n",
    "            margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0}\n",
    "        )\n",
    "        save_plot(fig_map, \"trajetoria_mapa.png\")\n",
    "        \n",
    "    # Tabela Resumo Estatístico\n",
    "    summary = df_results.describe().T[['mean', '50%', '75%', 'max']]\n",
    "    summary.columns = ['Média', 'Mediana', '75%', 'Max']\n",
    "    print(\"\\n--- Resumo Estatístico dos Erros (Metros) ---\")\n",
    "    display(summary.sort_values('Média'))\n",
    "\n",
    "else:\n",
    "    print(\"Nenhum resultado gerado para visualização.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
